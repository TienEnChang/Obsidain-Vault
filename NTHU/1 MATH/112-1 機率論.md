
Cheat Sheats:  [[Prob - Mid1.pdf|CS 1-1]] , Unlinked: [[comb-distrib-perm.jpg]], [[hypergeometric.jpg]]
Look Up Table:  [常態分配表 (ntu.edu.tw)](https://ie.ntu.edu.tw/dr_chen/Files/Service/normaltable.htm)

Extra
- [[Asymptotic - Big O, Small O]]
- [[112-2 機率論]]

New
- [[Moment Generating Function]]

Old
- [[List, Combination, Permutation]]
- [[Measure, Sigma Field]]
- [[Probability Space]] | [[Probability Space - Pf.|Pf.]]
- [[Random Variables, Functions - Def. & Thm.|Random Variables, Functions]]
- [[Expectation, Variance - Def. & Thm.|Expectation, Variance]] | [[Expectation, Variance - Pf.|Pf]]

01.08.24:
- $p_{X}(x)=dF_{X}(x)\,$ or $F_{X}(x)-\lim\limits_{\Delta x\to0}F_{X}(x-\Delta x)$  ( discrete $F_{X}$ only )
- $f_{X}(x)=\dfrac{dF_{X}(x)}{dx}$ or $\lim\limits_{\Delta x\to 0}\dfrac{p_{X}(x)}{\Delta x}$  { $\neq\dfrac{p_{X}(x)}{\Delta x}$ of Riemann Sum }
- $\implies$ 
	- ${\displaystyle\int}_{[a,\,b]}dF_{X}(x)={\displaystyle\int}_{[a,\,b]}f_{X}(x)dx={\displaystyle\int}_{[a,\,b]}p_{X}(x)$  { what is this? }


- multi
	- ![[Screenshot 2024-01-08 at 8.35.18 PM.png]]![[Screenshot 2024-01-08 at 8.35.02 PM.png]]![[Screenshot 2024-01-08 at 8.34.51 PM.png]]![[Screenshot 2024-01-08 at 8.34.36 PM.png]]![[Screenshot 2024-01-08 at 8.32.50 PM.png]]

- ordered statistics
	-  ![[Screenshot 2024-01-08 at 7.49.03 PM.png]]![[Screenshot 2024-01-08 at 7.45.31 PM.png]]![[Screenshot 2024-01-08 at 7.45.15 PM.png]]![[Screenshot 2024-01-08 at 7.44.52 PM.png]]![[Screenshot 2024-01-08 at 7.44.31 PM.png]]![[Screenshot 2024-01-08 at 7.44.14 PM.png]]![[Screenshot 2024-01-08 at 7.44.03 PM.png]]![[Screenshot 2024-01-08 at 7.43.41 PM.png]]

Rmk.
- $I_{[a,\,b]}(\,{}_{(d,\,\Delta)}F_{X}(x)\,)$
	- continuous:  $={\displaystyle\int}_{[a,\,b]}dF_{X}(x)={\displaystyle\int}_{[a,\,b]}f_{X}(t)dt$
	- discrete:  $=\sum\limits_{x \in[a,\,b]\cap\mathcal{X}}\Delta F_{X}(x)=\sum\limits_{k \in[a,\,b]\cap\mathcal{X}}p_{X}(k)$

Note
- discrete
	- ...
		- ![[N-trial Experiment]]
		
	- bernoulli
		- $X\sim{\rm Bernoulli}(p)$ $\equiv$ ${\rm binomial}(1,\,p)$
			- 
	- binomial:      $p_{X_{n}}(k)\coloneqq{n\choose k}\,p^k(1-p)^{(n-k)}$    $\mathcal{X}_{n}=\{0,\,\cdots,\,n\}$
			
		- $\mu=np\,$,  ${\sigma}^2=np(1-p)$
		- ...
			- ![[Binomial]]
		
	- geometric
		- $Y\sim{\rm geometric}(p)$ $\equiv$ $\text{neg-binomial}(1,\,p)$
			- 
	- neg-binomial:  $p_{\,Y_r}(k)\coloneqq{k-1\choose r-1}\,p^r(1-p)^{(k-r)}$    $\mathcal{Y}_r=\{r,\,r+1,\,\cdots\,\}$
			
		- $\mu=\dfrac{r}{p}\,$,  ${\sigma}^2=\dfrac{r}{p}\cdot\dfrac{(1-p)}{p}$
		- ...
			- ![[Neg-binomial]]
		
	- hyper-geo:     $p_X(k)\coloneqq\dfrac{{R\choose k}{N-R\choose n-k}}{N\choose n}$      $\mathcal{X}=\{0,\,\cdots,\,n\}$
			
		- $\mu=n\dfrac{R}{N}\,$,  ${\sigma}^2=n\dfrac{R}{N}\cdot(1-\dfrac{R}{N})(1-\dfrac{n-1}{N-1})$
		- ...
			- ![[Hyper-geo]]
		
	- poisson:       $p_{X}(k)\coloneqq\dfrac{\lambda^ke^{-\lambda}}{k!}$         $\mathcal{X}=\{0,\,1,\,\cdots\,\}$
		
		- $\mu={\sigma}^2=\lambda$
		- ...
			- ![[Poisson]]
	- poisson proc:  $p_{N_{t}}(k)\coloneqq\dfrac{(\overline{\lambda}t)^ke^{-(\overline{\lambda}t)}}{k!}$    $\,\mathcal{N}_{t}=\{0,\,1,\,\cdots\,\}$
		
	- multi-nomial:  $p_{X_{1},\,\cdots,\,X_{n}}(\vec{k})\coloneqq{m\choose k_{1},\,\cdots,\,k_{n}}\,p_{1}{^{\!k_{1}}}\cdots p_{n}{^{\!k_{n}}}$    $\mathcal{X}=\mathbb{N}_{\{0\}}{^{\!n}}\bigm|_{{\sum\limits_{i=1}^{n}k_{i}=m}}$
			
		- $\text{E}(X_{i}X_{j})$     $\,=(-n+n^{2})p_{i}p_{j}$
		- $\text{Cov}(X_{i},\,X_{j})$  $=-np_{i}p_{j}$
		- $\text{Cor}(X_{i},\,X_{j})$  $\,=-\sqrt{ \dfrac{p_{i}}{(1-p_{i})}\dfrac{p_{j}}{(1-p_{j})} }$
		- ...
			- ![[Multinomial]]
	
- continuous
	- uniform:  $F_{X}(x)\coloneqq\dfrac{x-a}{b-a}$    $\forall\,x \in[\,a,\,b\,]$
		
		- $\mu=\dfrac{a+b}{2}\,$,  $\sigma^{2}=\dfrac{(b-a)^{2}}{12}$
		- ...
			- $X\sim \text{uniform}(a,\,b)$  where  $a<b$
		
	- exp:      $F_{X}(x)\coloneqq1-e^{-\lambda x}$          $\forall\,x \in[\,0,\,\infty\,]$
			
		- $X\sim \text{exponential}(\lambda)$ $\equiv$ $\text{gamma}(1,\,\lambda)$  where  $\lambda>0$
			- 
	- gamma:    $F_{X}(x)\coloneqq\dfrac{1}{\Gamma(\alpha)}\,\gamma(\alpha,\,\lambda x)$    $\,\forall\,x \in[\,0,\,\infty\,]$
			
		- $f_{X}(x)\coloneqq\dfrac{\lambda}{\Gamma(\alpha)}\,\gamma'(\alpha,\,\lambda x)\,$,  $\mu=\dfrac{\alpha}{\lambda}\,$,  $\sigma^{2}=\dfrac{\alpha}{\lambda^{2}}$
			
		- $\gamma(\alpha,\, x)\coloneqq{\displaystyle\int}_{0}^{x}t^{\,\alpha-1}e^{-t}dt$
		- $\Gamma(\alpha)=\gamma(\alpha,\,\infty)\,$,  $\Gamma(n)=(n-1)!$  $\forall\,n \in \mathbb{N}$
		- ...
			- $X\sim \text{gamma}(\alpha,\,\lambda)$  where  $\alpha,\,\lambda>0$
		
	- beta:     $F_{X}(x)\coloneqq\dfrac{1}{B(\alpha,\,\beta)}\,B(x;\,\alpha,\,\beta)$    $\forall\,x \in[\,0,\,1\,]$
			
		- $\mu=\dfrac{\alpha}{\alpha+\beta}\,$,  $\sigma^{2}=\dfrac{\alpha \beta}{(\alpha+\beta)^{2}}\cdot\dfrac{1}{(\alpha+\beta+1)}$
			
		- $B(x;\,\alpha,\,\beta)\coloneqq{\displaystyle\int}_{0}^{x}t^{\alpha-1}(1-t)^{\beta-1}dt$
		- $B(\alpha,\,\beta)$ or $B(1;\,\alpha,\,\beta)=\dfrac{\Gamma(\alpha)\Gamma(\beta)}{\Gamma(\alpha+\beta)}$
		- ...
			- $X\sim \text{beta}(\alpha,\,\beta)$  where  $\alpha,\,\beta>0$
		
	- normal:   $F_{X}(x)\coloneqq\Phi(\dfrac{x-\mu}{\sigma})$    $\forall\,x \in(-\infty,\,\infty)$
			
		- $\Phi(x)\coloneqq {\displaystyle\int}_{-\infty}^{x}\dfrac{1}{\sqrt{ 2\pi }}\,e^{-\dfrac{t^{2}}{2}}dt$
		- $[\,\Phi(\dfrac{x-\mu}{\sigma})\,]'=\dfrac{1}{\sigma}\,\Phi'(\dfrac{x-\mu}{\sigma})$
		- ...
			- $X\sim \text{normal}(\mu,\,\sigma^{2})$  where  $\mu \in \mathbb{R}$, $\,\sigma>0$
	- ...
		- Cauchy:
			- $X\sim{\rm uniform}(-\dfrac{\pi}2,\,\dfrac{\pi}2)$ $\iff$ $(\sigma\tan(X)+\mu)\sim{\rm Cauchy}(\mu,\,\sigma)$
		- Weibull:
			- $X\sim{\rm exp}(\lambda)$ $\iff$ $(\alpha(\lambda X)^{\frac1{\beta}}+\nu)\sim{\rm Weibull}(\alpha,\,\beta,\,\nu)$
		- Chi-squared:
			- $X\sim{\rm gamma}(\alpha=\dfrac{n}2,\,\lambda=\dfrac12)$ $\equiv$ $\text{ chi-squared}(n)$ or $\chi^{2}(n)$
			- { $\mu=n$, $\sigma^{2}=2n$ }
	
- relation
	- (1) {dual: trial <> occur}![[Binomial <> Neg-binomial]]
	- (2) {dual: waiting time <> occur}![[Poisson <> Gamma]]
	- (3) {dual: discrete <> cont}![[Neg-binomial <> Gamma]]
	- (4) {approx}![[Binomial <> Hyper-geometric, Poisson]]
- relation (arithmetic)
	- ![[Gamma <> Beta]]
- relation (conditional)
	- (1)![[Poisson <> Multi-nomial]]
	- (2)![[Bournouli <> Beta]]

Note.
- probability space:  $(\Omega,\,\mathcal{F}_{\Omega},\,P)$   |  $\,\omega$, $E$  $\,$(outcome, event)
- digitized space:    $(\mathbb{R},\,\mathcal{F}_{\mathbb{R}},\,P_{X})$  |  $X$, $\mathcal{X}$  (random variable)
	- discrete: $\,|\mathcal{X}|=|\mathbb{N}|$
	- continuous: $\,|\mathcal{X}|=|\mathbb{R}|$  uncountable
- measure by event
	- $\mathcal{F}_{\Omega}\to[0,\,1]$:  $P$
		                {↓, $P_X(A)=P(X^{\leftarrow}(A))$ }
- measure by set:
	- $\mathcal{F}_{\mathbb{R}}\to[0,\,1]$:  $P_{X}\,\,$  
	                    {↑, $P_X(A)=\sum\limits_{k\in A\cap \mathcal{X}}p_X(k)$ }
	                    {↑, $P_X(A)={\displaystyle\int}_{A}f_{X}(t)dt$ }  
- measure by point
	- $\mathbb{R}\to[0,\,1]$
		- c.d.f.:  $F_{X}$  $\,\,${↓, $F_{X}(x)=P_{X}((-\infty,\,x\,])$ }
		- 
			            $\,${↓  $p_{X}(x)=P_{X}(\{x\})$ }
		- p.m.f.:  $p_{X}$   {↓, $p_{X}(x)=\Delta F_{X}(x)\,$ or $\,F_{X}(x)-F_{X}(x-\Delta x)$ }
		- p.d.f.:  $f_{X}$   {↓, $f_{X}(x)=F'_{X}(x)$  }
		- ...
			- discrete ← cont (partition => step-func)
				- $p_{X}(x)={\displaystyle\int}_{x-\Delta x}^{x}f(t)dt$
					- where  $\Delta x=\dfrac{b-a}{n}\,$, $\mathcal{X}=\big\{a+i\Delta x\}_{i=1}^{n}$
			- cont ← discrete (step-func => limit)
				- $f_{X}(x)=\lim\limits_{\Delta x\to0}\dfrac{p_{X}(x)}{\Delta x}$
		- ...
			- ![[Dist. Axiom]]

Note
- $\Omega \to \mathbb{R}$:  $1_E(\omega)\coloneqq\begin{cases}1&{\rm if}\;\omega\in E\\0&\text{o.w.}\end{cases}$
	- $p_{1_A}(k)=\begin{cases}P(E)&\text{if}\;k=1\\1-P(E)&\text{o.w.}\end{cases}$,  $\text{E}({1_E})=P(E)$

Note
- $\Omega_{0}{^{n}}\to \mathbb{R}$ (repeated):  $X_{n}(\omega )\coloneqq\sum\limits_{i=1}^{n}1_{E_{0}}(\omega_{i})$  |  $p_{X_{n}}(k\,;\,p=P_0(E_0))$
- $\Omega \to \mathbb{R}^{n}$  (joint):     $\textbf{X}(\omega)\coloneqq(X_{1}(w),\,\cdots,\,X_{n}(\omega))$
- where
	- $\mathcal{F}_{\mathbb{R}^{n}}\to[0,\,1]$: $\,\,P_{\textbf{X}}$  $\,${↑, $P_{\textbf{X}}(A)=\sum\limits_{\vec{k}\,\in A\cap \mathcal{X}}p_{\textbf{X}}(\vec{k})$ }
	                    {↑, $P_\textbf{X}(A)={\displaystyle\int}_{A}f_{\textbf{X}}(\vec{t\,})d\vec{t}$ }  
	- $\mathbb{R}^{n}\to[0,\,1]$
		- c.d.f.:  $F_{\textbf{X}}$  $\,\,${↓, $F_{\textbf{X}}(\vec{x})=P_{\textbf{X}}(\prod\limits_{i=1}^{n}(-\infty,\,x_{i}\,])$ }
			
		- p.m.f.:  $p_{\textbf{X}}$   {↓, $p_{\textbf{X}}(\vec{x})=\cdots$ }
		- p.d.f.:  $f_{\textbf{X}}$   {↓, $f_{\textbf{X}}(\vec{x})=\dfrac{ \partial^{n} }{ \partial x_{1}\cdots\partial x_{n} }F_{\textbf{X}}(\vec{x})$ }
	
- marginal  ($\mathbb{R}^{k}\subseteq \mathbb{R}^{n}$)
	- $p_{X_{i}}(x_{i})=\sum\limits_{\vec{k\,}\in[\,\mathbb{R}^{<i}\times \{x_{i}\}\times\mathbb{R}^{>i}\,]\cap \mathcal{X}}p_{\textbf{X}}(\vec{k})$   $\,${ $P_{\textbf{X}}([\,\mathbb{R}^{<i}\times \{x_{i}\}\times\mathbb{R}^{>i}\,])$ }
	- $f_{X_{i}}(x_{i})={\displaystyle\int}_{\mathbb{R}^{n-1}}f_{\textbf{X}}(\vec{x})\,dx_{<i}\,dx_{>i}$      { $\dfrac{ \partial  }{ \partial x_{i} }F_{\textbf{X}}(\vec{x})$ }
	
- conditional  ($\mathbb{R}^{k}\subseteq \mathbb{R}^{n}$)
	- $h_{X|Y}(x|y)=\dfrac{h_{X,\,Y}(x,\,y)}{h_{Y}(y)}$  for  $h_{Y}(y)>0$
		- multiplication law
			- $h_{\textbf{X}}(\vec{x})=h_{X_{1}}(x_{1})\,h_{X_{2}|X_{1}}(x_{2}|\,x_{1})\cdots h_{X_{n}|X_{1},\,\cdots,\,X_{n-1}}(x_{n}|\,x_{1},\,\cdots ,\,x_{n-1})$
		- Baysian Thm.
			- $p_{X|Y}(x|y)=\dfrac{p_{Y|X}(y|x)\,p_{X}(x)}{\sum\limits_{x \in \mathcal{X}}[\,p_{Y|X}(y|x)\,p_{X}(x)\,]}$ 
			- $f_{X|Y}(x|y)=\dfrac{f_{Y|X}(y|x)\,f_{X}(x)}{{\displaystyle\int}_{\mathbb{R}}[\,f_{Y|X}(y|x)\,f_{X}(x)\,]dx}$
			- $F_{X|Y}(x|y)=\dfrac{1}{{\displaystyle\int}_{(-\infty,\,\infty)}f_{(X,\,Y)}(t,\,y)dt}{{\displaystyle\int}_{(-\infty,\,x\,]}f_{(X,\,Y)}(t,\,y)dt}$
	
- independence
	- (1) $\{\,\vec{x}\;|\;h_{\textbf{X}}(\vec{x})>0\,\}$  is cross product set  { e.g. $1_{\{x+y\,\leq\,1\}}(x,\,y)$ [[Screenshot 2024-01-08 at 12.02.34 PM.png|not]] }
	- (2) $h_{\textbf{X}}(\vec{x})=\prod\limits_{i=1}^nh_{X_{i}}(x_{i})$  { seperable }
	- (3) $h_{X}(x)=h_{X|Y}(x|y)$ $\,\forall\,y$  { unaffected by condition }
		
	- $P_{\textbf{X}}(A_{1}\times \cdots\times A_{n})=\prod\limits_{i=1}^{n}P_{X_{i}}(A_{i})$
		- $\sum\limits_{(x,\,y)\in [A\times B]\cap [\mathcal{X}\times \mathcal{Y}]}p_{X,\,Y}(x,\,y)=\sum\limits_{x \in A\cap \mathcal{X}}p_{X}(x)\sum\limits_{y \in B\cap \mathcal{Y}}p_{Y}(y)$
		- ${\displaystyle\int}_{A\times B}f_{X,\,Y}(x,\,y)dxdy={\displaystyle\int}_{A}f_{X}(x)dx{\displaystyle\int}_{B}f_{Y}(y)dy$


 Transformation
- Let
	- $\textbf{Y}=g(\textbf{X})$
	- $g=(g_{1},\,\cdots,\,g_{k}):\mathbb{R}^{n}\to \mathbb{R}^{k}$  where  $g_{i}:\mathbb{R}^{n}\to\mathbb{R}$
	
- for $X$ univariate:
	- for $g$ strictly increasing:  $F_Y(y)=F_X(g^{-1}(y))$
	- for $g$ strictly decreasing:  $F_Y(y)=1-F_X(g^{-1}(y))$
	
- for $\textbf{X}$ multivariate:
	
- for any $g$:
	- $P_{\textbf{Y}}(A)=P_{\textbf{X}}(g^{\leftarrow}(A))=\sum\limits_{\vec{k} \in g^{\leftarrow}(A)\cap \mathcal{X}}p_{\textbf{X}}(\vec{k})$  or  ${\displaystyle\int}_{g^{\leftarrow}(A))}f_{\textbf{X}}(\vec{t\,})d\vec{t}$
- for $g$ bijective:
	- (1) $k=n$
	- (2) $g^{-1}=(g^{-1}{_{\!(1)}},\,\cdots,\,g^{-1}{_{\!(n)}})$  where  $g^{-1}{_{\!(i)}:\mathbb{R}^{n}\to \mathbb{R}}$
	- (3) $J_{(g^{-1})}=[\,\dfrac{ \partial g^{-1}{_{\!(i)}} }{ \partial y_{j} }\,]$,  $J_{(g)}=[\,\dfrac{ \partial g_{i} }{ \partial x_{j} }\,]$ 
	- $\implies$ 
		- $p_{\textbf{Y}}(\vec{y})=p_{\textbf{X}}(g^{-1}(\vec{y}))$
		- $f_{\textbf{Y}}(\vec{y})=f_{\textbf{X}}(g^{-1}(\vec{y}))\cdot|J_{(g^{-1})}|$  { diff. (+ cont.) }
	
- for $k=n$, $g_{i}:\mathbb{R}\to \mathbb{R}$
	- $(X_{1},\,\cdots,\,X_{n})$ indep. $\implies$ $(g_{1}(X_{1}),\,\cdots,\,g_{n}(X_{n}))$ indep.

Change of Coor.
- $Z=X+Y$:  $f_{Z}(z)={\displaystyle\int}_{\mathbb{R}}f_{X,\,Y}(x,\,z-x)dx$  { convolution }
- $Z=X-Y$:  $f_{Z}(z)={\displaystyle\int}_{\mathbb{R}}f_{X,\,Y}(z+y,\,y)dy$
- $Z=\dfrac{X}{Y}$:     $f_{Z}(z)= {\displaystyle\int}_{\mathbb{R}}f_{X,\,Y}(zy,\,y)\,|y|\,dx$
- $Z=XY$:    $f_{Z}(z)= {\displaystyle\int}_{\mathbb{R}}f_{X,\,Y}(x,\,\dfrac{z}{x})\dfrac{1}{|x|}dx$

Aggregation
- $\sum\limits_{i=1}^{n}:\mathbb{R}^{n}\to\mathbb{R}$
	- $X_{i}\sim \text{Poisson}(\lambda _{i})\,$ i.i.d $\implies$ $\sum\limits_{i=1}^{n}X_{i}\sim \text{Poisson}(\sum\limits_{i=1}^{n}\lambda_{i})$
	- $X_{i}\sim \text{gamma}(\alpha_{i},\,\lambda)\,$ i.i.d $\implies$ $\sum\limits_{i=1}^{n}X_{i}\sim \text{gamma}(\sum\limits_{i=1}^{n}\alpha_{i},\,\lambda )$
	- $X_{i}\sim \text{normal}(\mu_{i},\,\sigma_{i}{^{\!2}})\,$ i.i.d $\implies$ $\sum\limits_{i=1}^{n}X_{i}\sim \text{normal}(\sum\limits_{i=1}^{n}\mu_{i},\,\sum\limits_{i=1}^{n}\sigma_{i}{^{\!2}})$

Memoryless
- $\because$  $P_{(X_{1}+X_{2})}(\{x_{1}+x_{2}>a_{1}+a_{2}\})=\prod\limits_{i=1}^{2}P_{X_{i}}(\{x_{i}>a_{i}\})$  by i.i.d.
- $\therefore$  
	- geometric:    $P_{\,Y_1}(\{y>a+b\}\,|\,\{y>a\})=P_{\,Y_1}(\{y>b\})$
	- exponential:  $P_{\,T_1}(\{t>a+b\}\,|\,\{y>a\})=P_{\,T_1}(\{y>b\})$ 

Def.
- uniform dist. over $D$:  $f_{\textbf{X}}(\vec{x})=\dfrac{1}{\text{Area(D)}}1_{D}(\vec{x})$

Expectation 
- for $X$ univariate
	- $\text{E}(X)\coloneqq\sum\limits_{x \in\mathcal{X}}x\cdot p_{X}(x)$ or ${\displaystyle\int}_{\mathbb{R}}x\cdot f_{X}(x)dx\,$ or $S_{d\,(\mathbb{R})}(F_{X})$   { $\mu$ }
	- ${\rm Var}(X)\coloneqq \text{E}((X-\mu)^2)$     { $\sigma^{2}$ }
	- ...
		- (1) $\because$  $\sum\limits_{x\in \mathcal{X}}|\,[\cdot]\,|$ converges (absolutely)
		       $\,\therefore$  unaffected by change of order
		- (2) $\because$  $\sum\limits_{x\in \mathcal{X}}$  $\therefore$  unaffected by r.v.'s outcome
	
- for $\textbf{X}$ multivariate, $\,g:\mathbb{R}^{n}\to\mathbb{R}$
	- $\text{E}(g(\textbf{X}))=\sum\limits_{x \in\mathcal{X}}g(x)\cdot p_{\textbf{X}}(x)$ or ${\displaystyle\int}_{\mathbb{R}^{n}}g(x)\cdot f_{\textbf{X}}(x)dx\,$ or $S_{d\,(\mathbb{R}^{n})}(F_{\textbf{X}},\,g)$

\[ uni / multi ]

Thm.
- $\text{E}(a_{0}+\sum\limits_{i=1}^{n}(a_{i}X_{i}))=a_{0}+\sum\limits_{i=1}^{n}(a_{i}\,\text{E}(X_{i}))$
- $\text{Cov}(a_{0}+\sum\limits_{i=1}^{n}(a_{i}X_{i}),\,b_{0}+\sum\limits_{i=1}^{n}(b_{i}X_{i}))=\sum\limits_{1\leq i,\,j\leq n}a_{i}b_{j}\,\text{Cov}(X_{i},\,X_{j})$
Cor. 
- $\forall\,a,\,b\in\mathbb{R}$:  $\text{E}(a\,X+b)=a\,\text{E}(X)+b$ 
- $\forall\,a,\,b\in\mathbb{R}$:  ${\rm Var}(a\,X+b)=a^2\,{\rm Var}(X)$ ,  $\sigma_{(aX+b)}=|a|\,\sigma_X$

Thm.
- $\forall\,c\in\mathbb{R}$:  $E((X-c)^2)=\sigma^2+(\mu-c)^2$  [[Expectation, Variance - Pf.#^72cb9e|{Pf}]]
Cor.
- $\sigma^2=E(X^2)-\mu^2$

Rmk.
- $\text{E}(g(X))\not\equiv g(\text{E}(X))$

indep.
- average:  $X_{i}$ i.i.d. $\implies$ $\text{E}(\overline{X})=\text{E}(X_{i})$  $\forall\,i$  where  $\overline{X}=\dfrac{1}{n}\sum\limits_{i=1}^{n}X_{i}$
- product:
	- (1) indep. $\implies$ uncor.
	- (2) $X$ & $Y$ indep. $\implies$ $\text{E}(XY)=\text{E}(X)\,\text{E}(Y)$ ,  $\text{E}(\dfrac{X}{Y})\not\equiv\dfrac{\text{E}(X)}{\text{E}(Y)}$
	- (3) $\textbf{X}$ & $\textbf{Y}$ indep. $\implies$ $\text{E}(g_{1}(\textbf{X})\,g_{2}(\textbf{Y}))=\text{E}(g_{1}(\textbf{X}))\,\text{E}(g_{2}(\textbf{Y}))$

uncor.
- average:  $X_{i}$ u.i.d. $\implies$ $\text{Var}(\overline{X})=\dfrac{1}{n}\text{Var}(X_{i})$  $\forall\,i$  where  $\overline{X}=\dfrac{1}{n}\sum\limits_{i=1}^{n}X_{i}$
- linear combin.:
	- $(X_{1},\,\cdots,\,X_{n})\,$ uncor. 
		- $\implies$ $\text{Var}(a_{0}+\sum\limits_{i=1}^{n}(a_{i}X_{i}))=\sum\limits_{i=1}^{n}a_{i}{^{\!2}\,\text{Var}(X_{i})}$
			- else:  $\text{Var}(a_{0}+\sum\limits_{i=1}^{n}(a_{i}X_{i}))=\sum\limits_{i=1}^{n}a_{i}{^{\!2}\,\text{Var}(X_{i})}+2\sum\limits_{1\leq i<j\leq n}a_{i}a_{j}\,\text{Cov}(X_{i},\,X_{j})$

Rmk.
- i.i.d.: indep., identical dist.
- u.i.d.: uncor., identical dist.


Prop.
- $P_{X,\,Y}(\{x\geq y\})=1$ $\implies$ $\text{E}(X)\geq \text{E}(Y)$
	- since  $P_{X,\,Y}(\{x<y\})=0$

Cor.
- $P_{X}[\,a,\,b\,]=1$ $\implies$ $\text{E}(X)\in[a,\,b]$



Covariance, Correlation


$\text{Cov}(X,\,Y)=\text{E}((X-\mu_{X})(Y-\mu_{Y}))$  { $\sigma_{XY}$ }

$\text{Cor}(X,\,Y)=\text{E}((\dfrac{X-\mu_{X}}{\sigma_{X}})(\dfrac{Y-\mu_{Y}}{\sigma_{Y}}))$ or $\dfrac{\sigma_{XY}}{\sigma_{X}\sigma_{Y}}$  { $\rho_{XY}$ }

Rmk. $\text{Var}(X)=\text{Cov}(X,\,X)$  { "co"-variance }

uncorrelated:  $\rho_{XY}=0$  i.e. $\,\sigma_{XY}=0$

Thm.
- $\text{Cov}(X,\,Y)=\text{E}(XY)-\text{E}(X)\,\text{E}(Y)$




===



Thm. Birthday problem 
- prob of $n$ people all diff. birthday: $P(E)=\dfrac{\#E}{\#\Omega}=\dfrac{(365)_n}{365^n}$

![[Screenshot 2023-10-23 at 6.59.27 PM.png]]
![[Screenshot 2023-10-23 at 7.00.39 PM.png]]


---


Show is p.m.f.
- binomial theorem:  Oct 24
- negative binomial theorem:  Oct 31
- hypergeometric identity:  Nov 02

discrete:  only countable {point} possible value ($>0$)
continuous:  allow uncountable {interval} possible value (??)

Real-life
- dense countable subset of interval (uncountable) => use continuous

==

P(B|A) = P(A$\cup$B)/P(A)  $\because$ P(A$^c\cup$B) has become 0, updated info

P(A|B):  “已知” B 發生，A 發生？ ,  devide and conquer

probability
- is about <u>unknown</u> information of a event
- is a measurement

- random
![[Screenshot 2023-09-12 at 11.03.10 AM.png]]
- deterministic
![[Screenshot 2023-09-12 at 11.03.26 AM.png]]

vs.
- deterministic: $p\in\{0,\,1\}$
- random: $p\in[0,\,1]$
	- high => predictable ↑, entropy ↓
	- low  => predictable ↓, entropy ↑

evolution: information ↑ => randomness ↓
- conditional / bayesian

Ex.
- Invoice Checking (Sampling Proportional to Size)

Interpretation
- 客觀 Objective:  has to be "repeatable" (重複試驗) => frequency
- 主觀 Subjective