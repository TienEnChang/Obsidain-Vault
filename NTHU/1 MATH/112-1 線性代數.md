
Part 1
- [[Vector Space, Subspace]]   | [[Vector Space, Subspace - Sub|Sub]] | [[Vector Space, Subspace - Pf|Pf]]
- [[Common Vector Spaces]]     | [[Common Vector Spaces - Sub|Sub]]
- [[Generating Set, Span]]
- [[Linearly Independent Set]]
- [[Basis]]                    | [[Basis - Pf|Pf]]

Part 2
- [[Linear Transformation]]
- [[Space of Linear Transformation]]
- [[Matrix Representation]]
- [[Inverse, Isomorphism]]

Part 3
- [[Matrix - Rank]]
- [[System of Linear Equations - Theory - Pf.]]  {is Pf}
- [[System of Linear Equations - Computation, RREF]]
- [[N-linear, Alternating]]

Part 4
- [[Summary]]

Tool
- [Matrix Multiplication Calculator (reshish.com)](https://matrix.reshish.com/multiplication.php)


===


===

Rmk. basis transformation's det:  $\det([I_{V}]^{\beta'}_{\beta})\neq 0$

Review
- $Ax=b$, $(A|b)$
- $w(i,\,j)_{kl}\coloneqq\begin{cases}\delta_{kl}&\text{if}\;k\neq i,\,j\\\delta_{jl}&\text{if}\;k=i\\ \delta_{il}&\text{if}\;k=j\end{cases}$
	- row switching:     $w(i,\,j)A$
	- column switching:  $A\,w(i,\,j)$   { $w(i,\,j)^{\top}=w(i,\,j)$ }
- $d_{i}(a)\coloneqq\begin{cases}\delta_{kl}&\text{if}\;k\neq i\\ a\cdot\delta_{il}&\text{if}\;k=i\end{cases}$
	- row multiply:     $d_{i}(a)A$
	- column multiply:  $A\,d_{i}(a)$     { $d_{i}(a)^{\top}=d_{i}(a)$ }
- $e_{ij}(a)\coloneqq\begin{cases}\delta_{kl}&\text{if}\;k\neq i\\ \delta_{il}+a\cdot \delta_{jl}&\text{if}\;k=i\end{cases}$
	- row switching:     $e_{ij}(a)A$
	- column switching:  $A\,e_{ji}(a)$   { $e_{ij}(a)^{\top}=e_{ji}(a)$ }



\[ In $M_2(F)$ ]

Prop.
- $\rm det$ is bilinear
	- i.e.  ${\rm det}(\begin{bmatrix} u +cv\\ w \end{bmatrix})={\rm det}(\begin{bmatrix} u\\ w \end{bmatrix})+c\cdot{\rm det}(\begin{bmatrix} v\\ w \end{bmatrix})$
	        ${\rm det}(\begin{bmatrix} w\\ u +cv \end{bmatrix})={\rm det}(\begin{bmatrix} w\\ v \end{bmatrix})+c\cdot{\rm det}(\begin{bmatrix} w\\ u \end{bmatrix})$
- ${\rm det}(\begin{bmatrix} u\\ w \end{bmatrix})=-{\rm det}(\begin{bmatrix} w\\ u \end{bmatrix})$
- ${\rm det}(AB)={\rm det}(A)\cdot {\rm det}(B)$
- ${\rm det}(A^t)={\rm det}(A)$

Def.
- sign of $x\in\mathbb{R}$:   ${\rm sgn}(x) :=\begin{cases} 1 & \text{if } x > 0 \\0 & \text{if } x = 0 \\-1 & \text{if } x < 0 \end{cases}$  $\implies$  $\forall\,x\neq 0$: ${\rm sgn}(x)=\dfrac{x}{|x|}$
- sign of $\sigma\in S_n$:  ${\rm sgn}(\sigma):=(-1)^{N(\sigma)}$

Def.
- orientation:  $O(\begin{bmatrix} u \\ v \end{bmatrix})\coloneqq{\rm sgn}({\rm det}(\begin{bmatrix} u \\ v \end{bmatrix}))$,  $O(\begin{bmatrix} u \\ v \end{bmatrix})^2=1$
- area:         $\mathcal{A}(\begin{bmatrix} u \\ v \end{bmatrix})=O(\begin{bmatrix} u \\ v \end{bmatrix})\cdot {\rm det}(\begin{bmatrix} u \\ v \end{bmatrix})=|{\rm det}(\begin{bmatrix} u \\ v \end{bmatrix})|$


\[ In $M_n(F)$ ]

Let $A\in M_n(F)$

Def.
- general linear group:  $GL(n,\,\mathbb{R})\coloneqq\det^{\leftarrow}(\mathbb{R}-\{0\})$,  $\subseteq M_n(\mathbb{R})$
- special linear group:  $SL(n,\,\mathbb{R})\coloneqq\det^{\leftarrow}(\{1\})$,      $\subseteq M_n(\mathbb{R})$

Def.
- submatrix: $\widetilde{A}(i,\,j)\coloneqq[$ deleting $A$'s $i$th row & $j$th col $]\in M_{n-1}(F)$

Def.
- det's cofactor expansion (1st row):
	- ${\rm det}(A)\coloneqq\begin{cases} A_{11} & {\rm if}\;n=1 \\ \sum\limits_{j=1}^n [ A_{1j}\cdot(-1)^{1+j}\cdot{\rm det}(\widetilde A(1,\,j))] & {\rm if}\;n>1 \end{cases}$   (recursive method)

---

Prop. Multilinear Property
- ${\rm det}(\begin{bmatrix} \vdots\\ u +cv\\ \vdots \end{bmatrix})={\rm det}(\begin{bmatrix} \vdots\\ u\\ \vdots \end{bmatrix})+c\cdot{\rm det}(\begin{bmatrix} \vdots\\ v\\ \vdots \end{bmatrix})$  where  $u,\,v\in F^n$, $c\in F$
Cor.
- ${\rm det}(\begin{bmatrix} \vdots\\ \vec 0\\ \vdots \end{bmatrix})=0$

Thm. det's cofactor expansion (along $i$th row)
- For $n>1$,
	- ${\rm det}(A)\coloneqq\sum\limits_{j=1}^n [ A_{ij}\cdot(-1)^{i+j}\cdot{\rm det}(\widetilde A(i,\,j))]$
Cor.
- ${\rm det}(\begin{bmatrix} \vdots\\ u\\ \vdots \\ u\\\vdots \end{bmatrix})=0$

Prop.
- ${\rm det}(w(i,\,j))=-1$,  ${\rm det}(d_i(a))=a$,  ${\rm det}(e_{ij}(a))=1$

det neq 0  iff  invertible 

Prop.
- ${\rm det}(-I_n)=(-1)^n$  by diagonal formula

Prop.
- ${\rm det}$ is "$\,\cdot\,$"-invariant operator
- $\rm tr$ is "$+$"-invariant operator

Prop.
- operator:  transformation on itself ($V\to V$

Pf.
- 
	![[Screenshot 2023-12-19 at 6.29.50 PM.png]]
	![[Screenshot 2023-12-19 at 6.30.31 PM.png]]
	![[Screenshot 2023-12-19 at 6.31.30 PM.png]]
	![[Screenshot 2023-12-19 at 6.32.27 PM.png]]
	![[Screenshot 2023-12-19 at 6.32.50 PM.png]]
	![[Screenshot 2023-12-19 at 6.34.18 PM.png]]
	![[Screenshot 2023-12-19 at 6.34.46 PM.png]]
	![[Screenshot 2023-12-19 at 6.35.12 PM.png]]

![[Screenshot 2023-12-19 at 6.55.27 PM.png]]


![[Screenshot 2023-12-19 at 5.05.18 PM.png]]


Note
- $\dim(A\oplus B)=\dim(A)+\dim(B)$  $\forall\,A,\,B\subseteq V$


Def. elementary operations
                     { row }             { column }
(1) switch            $[\;I_{i\,\square}$ $\leftrightarrow$ $I_{j\,\square}\,]$         $[\;I_{\square\,i}$ $\leftrightarrow$ $I_{\square\,j}\,]$
(2) multiply ($a\neq 0$)  $\,[\;I_{i\,\square}$ $\leftarrow$ $a\,I_{i\,\square}\,]$       $\;[\;I_{\square\,i}$ $\leftarrow$ $a\,I_{\square\,i}\,]$
(3) add ($i\neq j$)       $\;\,[\;I_{i\,\square}$ $\leftarrow$ $a\,I_{j\,\square}+I_{i\,\square}\,]$  $[\;I_{\square\,i}$ $\leftarrow$ $a\,I_{\square\,j}+I_{\square\,i}\,]$

Def. elementary matrix
- row: $E\cdot A$
- column: $A\cdot E$
- $\implies$
- (explicit form)
	- $w(i,\,j)\coloneqq I_n-E^{ii}-E^{jj}+E^{ij}+E^{ji}$   { $=w^{\rm [col]}(i,\,j)$ }
	- $d_i(a)\coloneqq I_n+(a-1)E^{ii}\,$              { $={d_i}^{\rm [col]}(a)$ }
	- $e_{ij}(a)\coloneqq I_n+a\,E^{ij}\;$                  { $[\ldots]^\top={e_{ij}}^{\rm [col]}(a)$ }
- $\implies$
- (inverse)
	- $w(i,\,j)^{-1}=\,w(j,\,i)$
	- $d_i(a)^{-1}=d_i(a^{-1})$
	- $e_{ij}(a)^{-1}=e_{ij}(-a)$   (remain same type)

Review
- $Ax=b$, $(A|b)$
- $w(i,\,j)_{kl}\coloneqq\begin{cases}\delta_{kl}&\text{if}\;k\neq i,\,j\\\delta_{jl}&\text{if}\;k=i\\ \delta_{il}&\text{if}\;k=j\end{cases}$
	- row switching:     $w(i,\,j)A$
	- column switching:  $A\,w(i,\,j)$   { $w(i,\,j)^{\top}=w(i,\,j)$ }
- $d_{i}(a)\coloneqq\begin{cases}\delta_{kl}&\text{if}\;k\neq i\\ a\cdot\delta_{il}&\text{if}\;k=i\end{cases}$
	- row multiply:     $d_{i}(a)A$
	- column multiply:  $A\,d_{i}(a)$     { $d_{i}(a)^{\top}=d_{i}(a)$ }
- $e_{ij}(a)\coloneqq\begin{cases}\delta_{kl}&\text{if}\;k\neq i\\ \delta_{il}+a\cdot \delta_{jl}&\text{if}\;k=i\end{cases}$
	- row switching:     $e_{ij}(a)A$
	- column switcfhing:  $A\,e_{ji}(a)$   { $e_{ij}(a)^{\top}=e_{ji}(a)$ }
















Pf.
- ${\rm dim}({\rm rng}(T))={\rm dim}({\rm rng}(\phi_\gamma\circ{{\rm rng}(T)}))={\rm dim}({\rm rng}(L_{[T]_\beta^\gamma}\circ{\phi_\beta}))={\rm dim}({\rm rng}(L_{[T]_\beta^\gamma}))$
	     { ${\phi_\gamma}$ iso }          { commutative }       { ${\phi_\beta}$ iso }

Pf.
- ${\rm rng}(L_A)={\rm span}\{L_A(\beta_1),\,\cdots,\,L_A(\beta_n)\}$  where  $[L_A(\beta_i)]_\gamma$ is ith column

Pf.
![[Screenshot 2023-12-05 at 6.48.15 PM.png]]

![[Screenshot 2023-12-05 at 6.49.01 PM.png]]
![[Screenshot 2023-12-05 at 6.49.34 PM.png]]




![[Screenshot 2023-12-05 at 6.42.34 PM.png]]

助教課：commutative diagram of dual space { $\psi_2(T)=T^{tt}(\psi_1)$ }

Matrix is similar = is conjugate

Def. elementary
- row operation:  $w(i,\,j)\cdot A$
- column operation:  $A\cdot w(i,\,j)$


Thm. commutative diagram
- $T:V\to W$
- $\implies$ $[T]_\beta^\gamma\in M_{m\times n}(F)$ , $L_{[T]_\beta^\gamma}:F^n\to F^m$.  $\phi_\beta:V\overset{\rm iso}{\to}F^n$ , $\phi_\gamma:W\overset{\rm iso}{\to}F^m$
- $\implies$ $L_{[T]_\beta^\gamma}(\phi_\beta)=\phi_\gamma(T)$


---

Def. Lagrange polynomials
- $l_i(x)=\prod\limits_{0\leq j\leq n\,,\;j\neq i}(\dfrac{x-x_j}{x_i-x_j})$  where  $x_0,\,...,\,x_n\in F$
- $\implies$
	- $l_i(x_j)=\begin{cases}1&{\rm if}\;i=j\\0&{\rm o.w.}\end{cases}$ ,  $\{\,l_0(x),\,...,\,l_n(x)\,\}$ is a basis of $P_n(F)$

Thm. Lagrange interpolation formula
- $\forall\,(x_0,\,y_0),\,...,\,(x_n,\,y_n)\in F^2$ ,  $y_0,\,...,\,y_n$ distinct:
  $\exists\,!\,L\in P_n(F)$  where  $L(x)\coloneqq\sum\limits_{i=0}^ny_il_i(x)$
                s.t. $L(x_i)=y_i$  $\forall\,i=0,\,...,\,n$

===

Let $T:V\to W$ be linear

Thm.
- $T$ is linear $\implies$ $T(0_v)=0_w$
- $T$ is linear $\iff$ $T(\sum\limits_{i=1}^na_i\,x_i)=\sum\limits_{i=1}^na_i\,T(x_i)$
Cor.
- $\forall\,x\in V$:  $\exists\,(a_1,\,...,\,a_n)$ in $F$  s.t.
	- $x=\sum\limits_{i=1}^na_i\beta_i$
	- $T(x)=\sum\limits_{i=1}^na_i\,T(\beta_i)$  i.e.  $T(\beta)$ is the basis of $T(V)$
	                    i.e.  $T(V)={\rm Span}(T(\beta))$


\[ For any ${\rm dim}(V)$, ${\rm dim}(W)$ ]

Thm. $T(V)={\rm Span}(T(\beta))$

Thm. Dimension Thm.
- ${\rm dim}(V)-{\rm dim}(\,N(T)\,)={\rm dim}(\,T(V)\,)$

Thm. $T$ is 1-1 $\iff$ $N(T)=\{\vec 0_v\}$

Thm. 
- $T$ isomorphism
- $\iff$ $[T]_\beta^\gamma$ is invertible  \[ ${\rm dim}<\infty$ ]
- $\implies$ $T^{-1}$ isomorphism

     { Def. linear & invertible }
Thm. $T$ isomorphism $\implies$ $V$, $W$ are isomorphic
                        { Def. $\exists$ isomorphism $T:V\to W$ }

Thm. $V$, $W$ are isomorphic $\iff$ ${\rm dim}(V)={\rm dim}(W)$

Thm.
- ${\rm dim}(V)={\rm dim}(W)$
- $\implies$
- T.A.F.E.
   (1) $T$ is 1-1
   (2) $T$ is onto.  together $\implies$ $T$ bijective { invertible $\forall\,f$ }


===

Note
- odd / even:  (v) $x\in-\mathbb{N}$  (x)  $x\in\mathbb{R}-\mathbb{Z}$
- [[Direct sum, Coset, Quotient Space]]
Q
- why $\dim(V/N(T))=\dim(V)-\dim(N(T))$ ?? look for proof in dim thm.

===

Rmk. Def.
- linear isomorphism between $V$, $F^n$: 
	- $T_{\beta}:F^n\to V$  with  $(a_1,...,a_n)\mapsto\sum\limits_{k=1}^{n}a_k\,u_k$
	- where
		- $V$ is finite dimensional, with basis $\beta=\{u_1,...,u_n\}$
		- $T_{\beta}$ is bijective

Def.
- composition of linear transformation:
	- $T:V\to W$, $U:W\to Z$
	- $z=U\circ T(x)$ ${\overset{\rm iso}\sim}$ $[U]_\gamma^\zeta[T]_\beta^\gamma[x]_\beta=[z]_{\zeta}$ 

===

Prop.
- differential & integral are linear transformation
- $\dfrac{d}{dx}(f+g)(x)=\dfrac{d}{dx}f(x)+\dfrac{d}{dx}g(x)$
- $\displaystyle\int_0^t(f+g)(x)dx=\int_0^tf(x)dx+\int_0^tg(x)dx$

Thm.
- $\beta$ is a basis of $V$
- $\iff$
	- $\forall\,\vec v\in V$:  $\exists\,!$ finite $N_\beta\subseteq\beta$, $\exists\,!\,\{a_{\vec u}\}_{\vec u\in N_\beta}\subseteq F$  s.t. $\vec v=\sum\limits_{\vec u\in N_\beta}a_{\vec u}\vec u$
	  i.e.  uniquely expressible as a 
	        linear combination of finitely many vectors in $\beta$

Def.
- rotation: $T_\theta:\mathbb{R}^2\to\mathbb{R}^2$  where  $T_\theta\,(a_1,\,a_2)\coloneqq\begin{bmatrix}\cos(\theta) & -\sin(\theta)\\\sin(\theta) & \cos(\theta) \end{bmatrix}\begin{bmatrix}a_1\\a_2 \end{bmatrix}$
- reflection by x-axis: $T:\mathbb{R}^2\to\mathbb{R}^2$  where  $T(a_1,\,a_2)\coloneqq(a_1,\,-a_2)$

Thm. transpose $(\cdot)^t$ is linear



