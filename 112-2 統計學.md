

When $n$ is large,

$\text{P}([\overline{X}-\mu]\in[-c,\,c])=\text{P}(\dfrac{\overline{X}-\mu}{\sqrt{ \frac{\sigma^{2}}{n} }})\in[\dfrac{-c}{\sqrt{ \frac{\sigma^{2}}{n} }},\,\dfrac{c}{\sqrt{ \frac{\sigma^{2}}{n} }}]$

$$



Q.
- consistent vs. unbias

Def.
- $X_{n}\to \alpha$ in pr.:
	- $\lim\limits_{n\to\infty}\text{P}(X_{n} \in[\alpha-\delta ,\, \alpha+\delta])=1$  $\forall\,\delta>0$
		- OR
	- $\lim\limits_{n\to\infty}\text{P}(X_{n} \in[\alpha-\delta ,\, \alpha+\delta])=0$  $\forall\,\delta>0$

Thm.
- $g$ continuous  $\land$  $X_{n}\to \alpha$ in pr. $\implies$ $g(X_{n})\to g(\alpha)$ in pr.

Def.
- $X_{n}\to X$ in dist.:
	- $F_{n}(x)\to F(x)$
	- where
		- $X_{n}\sim F_{n}$,  $X\sim F$
		- $F_{n}(x)\coloneqq \text{P}(X_{n}\leq x)=S(\cdots)$
		- $F(x)\coloneqq \text{P}(X\leq x)=S(\cdots)$
By
- $\text{E}(X^{r})=\text{E}(X)$

Def.
- $\overline{X_{n}}\coloneqq\dfrac{1}{n}\sum\limits_{i=1}^{n}X_{i}$
- $X_{i}$ i.i.d.:  $\text{E}(X_{i})=\mu$, $\text{Var}(X_{i})=\sigma^{2}$

Thm.
- $\overline{X_{n}}\to \mu$ in pr.
Cor.
- $\sup\limits_{i\geq 1}$


Cauchy-Schwart's
- $|\text{E}(XY)|\leq \sqrt{ \text{E}(X^{2})\text{E}(Y^{2}) }$
Note
- $\text{E}(XY)=\text{E}(X)\text{E}(Y)$  if indep.

===

統計 is inferring {distribution of 母體} from {outcomes observed}
- step
	- 收集資料
	- 建立模型："特徵選取"、顯著性檢定
	- 參數估計
		- 點估計 = 期望值？
		- 區間估計 dependent on 樣本數
	- 預測
		- 點預測
		- 區間預測

Thm. Markov inequality
- $\text{P}(x\geq c)\leq\dfrac{E(x)}{c}$
Pf.
Let $X$ be non-negative r.v.
$\text{E}(x)={\displaystyle\int}_{0}^{\infty}xf(x)dx\geq{\displaystyle\int}_{c}^{\infty}cf(x)dx=c\cdot\text{P}(x\geq c)$

Cor. Chebyshev inequality
- $\text{P}(|x-\mu|\geq c))\leq\dfrac{\sigma}{c^{2}}$
Pf.
$\text{P}(|x-\mu|\geq c)=\text{P}((x-\mu)^{2}\geq c^{2})\leq\dfrac{\sigma}{c^{2}}$

Lemma. 
- $X_{i}$ i.i.d. $\land$  $\overline{X}_{n}\coloneqq\dfrac{1}{n}\sum\limits_{i=1}^{n}X_{i}$
- $\implies$
	- $\text{E}(\overline{X}_{n})=\mu$  or  $\text{E}(X_{i})$ $\forall\,i$ 
	- $\text{Var}(\overline{X}_{n})=\dfrac{\sigma^{2}}{n}$  or  $\dfrac{1}{n^{2}}\sum\limits_{i=1}^{n}\text{Var}(X_{i})$ {why?}

Thm. Weak Law of Large Numbers
- $X_{i}$ i.i.d. $\land$  $\overline{X}_{n}\coloneqq\dfrac{1}{n}\sum\limits_{i=1}^{n}X_{i}$
- $\implies$
	- $\lim\limits_{n\to\infty}\text{P}(|\overline{X}_{n}-\mu|\geq\varepsilon)=0$  $\forall\,\varepsilon>0$
Pf.
$\text{P}(|\overline{X}_{n}-\mu|\geq\varepsilon)\leq\dfrac{\text{Var}(\overline{X}_{n})}{\varepsilon^{2}}\leq\dfrac{\sigma^{2}}{n\varepsilon^{2}}\to0$  as  $n\to0$


Rmk.
- Still holds if:
	- (1) $X_{i}$ i.i.d. weakend to pairwise uncorrelated. Why?
	- (2) $\sigma \neq \infty$

Lemma.
- $X_{i}$ pairwise uncorrelated { $\text{Cov}(X_{i},\,X_{j})=0$ $\forall\,i\neq j$ }
- $\implies$ 
	- $\text{Var}(\overline{X}_{n})=\dfrac{1}{n^{2}}\text{Var}(\sum\limits_{i=1}^{n}X_{i})$
	- $=\dfrac{1}{n^{2}}\text{E}([\sum\limits_{i=1}^{n}X_{i}-\mu]^{2})$
	- $=\dfrac{1}{n^{2}}\text{E}([\sum\limits_{i=1}^{n}X_{i}-\mu][\sum\limits_{j=1}^{n}X_{j}-\mu])$
	- $=\dfrac{1}{n^{2}}\text{E}(\sum\limits_{i=1}^{n}\sum\limits_{j=1}^{n}[X_{i}-\mu][X_{j}-\mu])$
	- $=\dfrac{1}{n^{2}}\sum\limits_{i=1}^{n}\sum\limits_{j=1}^{n}\text{E}([X_{i}-\mu][X_{j}-\mu])$
	- $=\dfrac{1}{n^{2}}\sum\limits_{i=1}^{n}\text{E}([X_{i}-\mu]^{2})$
		- since  $\text{E}([X_{i}-\mu][X_{j}-\mu])=\text{Cov}(X_{i},\,X_{j})$
	- $=\dfrac{\sigma^{2}}{n}$